# @package _global_

defaults:
  - override /datamodule: bose_hubbard_2d
  - override /lit_model: lit_dmb_model
  - override /lit_model/model: dmb_model
  - override /callbacks: default
  - override /trainer: default
  - _self_

exp_name: "bose_hubbard_2d/worm/all_obs/mse/softplus"

seed: 12345

trainer:
  max_epochs: 1
  accumulate_grad_batches: 4
  precision: 16-mixed
  deterministic: False
  val_check_interval: 5

datamodule:

  batch_size: 1024

  split:
    _target_: dmb.data.split.Split.from_file
    file_path: ${paths.data_dir}/splits/bose_hubbard_2d/random/2024-04-15_19-05-07.json

  dataset:
    _target_: dmb.data.bose_hubbard_2d.worm.dataset.BoseHubbardDataset
    clean: True
    reload: False
    verbose: False
    check_readable: True
    transforms: 
      _target_: dmb.data.bose_hubbard_2d.transforms.BoseHubbard2dTransforms
      train_augmentations:           
        - _target_: dmb.data.bose_hubbard_2d.transforms.SquareSymmetryGroupAugmentations

lit_model:
  model:

    module_list: [
      {
        _target_: dmb.model.models.simple_resnet2d.ResNet2d,
        in_channels: 4,
        out_channels: 9,
        kernel_sizes: [5,3,3,3,3,3,3,3,3],
        n_channels: [16,32,64,128,128,128,256,256,256],
        dropout: 0.1
      },
    ]

    output_modification: [
      _target_: torch.nn.Softplus
    ]

  optimizer:
    lr: 0.005

  lr_scheduler:
    scheduler:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      mode: min
      factor: 0.5
      patience: 200
      min_lr: 1e-4
      cooldown: 500
      threshold: 0.1
      
    monitor: val/mse
    interval: epoch
    frequency: 1

  loss:
    _target_: dmb.model.loss.MSELoss
    reduction: mean