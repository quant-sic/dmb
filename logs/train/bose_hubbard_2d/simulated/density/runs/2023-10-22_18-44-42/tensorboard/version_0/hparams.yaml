model:
  _target_: dmb.model.dmb_model.DMBModel
  in_channels: 4
  out_channels: 1
  observables:
  - Density_Distribution
  module_list:
  - _target_: dmb.model.models.simple_resnet2d.SeResNet2d
    in_channels: 4
    out_channels: 1
    kernel_sizes:
    - 5
    - 3
    - 3
    - 3
    - 3
    - 3
    - 3
    - 3
    n_channels:
    - 16
    - 32
    - 64
    - 128
    - 128
    - 256
    - 256
    - 256
    dropout: 0.1
  output_modification:
  - _target_: dmb.model.dmb_model.Exponential
model/params/total: 3981216
model/params/trainable: 3981216
model/params/non_trainable: 0
datamodule:
  _target_: dmb.data.bose_hubbard_2d.simulated.datamodule.SiumlatedBoseHubbardDataModule
  batch_size: 256
  num_workers: 4
  base_transforms: null
  train_transforms:
    _target_: torchvision.transforms.transforms.Compose
    transforms:
    - _target_: dmb.data.utils.SquareSymmetryGroupAugmentations
  num_samples: 5000
  observables:
  - Density_Distribution
trainer:
  _target_: lightning.pytorch.Trainer
  default_root_dir: /Users/fabian/paper/dmb/logs/train/bose_hubbard_2d/simulated/density/runs/2023-10-22_18-44-42
  min_epochs: 1
  max_epochs: 1000
  accelerator: auto
  devices: 1
  check_val_every_n_epoch: 1
  deterministic: true
  log_every_n_steps: 25
  fast_dev_run: false
  gradient_clip_val: 1
  accumulate_grad_batches: 4
callbacks:
  model_checkpoint_best:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: /Users/fabian/paper/dmb/logs/train/bose_hubbard_2d/simulated/density/runs/2023-10-22_18-44-42/checkpoints/best
    filename: '{epoch}-{step}'
    monitor: val/loss
    verbose: false
    save_last: null
    save_top_k: 3
    mode: min
    auto_insert_metric_name: true
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  model_checkpoint_regular:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: /Users/fabian/paper/dmb/logs/train/bose_hubbard_2d/simulated/density/runs/2023-10-22_18-44-42/checkpoints/regular
    filename: '{epoch}-{step}'
    monitor: val/loss
    verbose: false
    save_last: null
    save_top_k: -1
    mode: min
    auto_insert_metric_name: true
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: 10
    save_on_train_epoch_end: null
  model_summary:
    _target_: lightning.pytorch.callbacks.ModelSummary
    max_depth: -1
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar
  lr_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: null
    log_momentum: false
extras:
  ignore_warnings: false
  enforce_tags: true
  print_config: true
task_name: train
tags:
- simulated
- bose_hubbard_2d
- resnet
- density
ckpt_path: null
seed: 12345
optimizer:
  _target_: torch.optim.Adam
  lr: 0.0001
  weight_decay: 0.0
scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: min
  factor: 0.5
  patience: 200
  min_lr: 1.0e-05
  verbose: false
  cooldown: 100
  threshold: 0.1
loss:
  _target_: dmb.model.utils.MSLELoss
  reduction: mean
observables:
- Density_Distribution
num_samples: 5000
train_val_test_split:
- 0.8
- 0.1
- 0.1
batch_size: 256
num_workers: 4
base_transforms: null
train_transforms:
  _target_: torchvision.transforms.transforms.Compose
  transforms:
  - _target_: dmb.data.utils.SquareSymmetryGroupAugmentations
resplit: null
split_usage:
  train: 0
  val: 1
  test: 2
pin_memory: false
save_split_indices: true
muU_range:
- -0.5
- 3.0
ztU_range:
- 0.05
- 1.0
zVU_range:
- 0.75
- 1.75
L_range:
- 8
- 20
z: 4
