# @package _global_

# Test the Lucas dataset with all columns

defaults:
  - override /datamodule: bose_hubbard_2d
  - override /model: dmb_lit_model
  - override /model/model: dmb_model
  - override /callbacks: default
  - override /trainer: default
  - _self_

tags: ["test", "bose_hubbard_2d", "resnet"]

seed: 12345

trainer:
  max_epochs: 10000
  gradient_clip_val: 1
  accumulate_grad_batches: 8

exp_name: "bose_hubbard_2d/worm/se_cnn/all_obs/mse/none"

test: True

datamodule:

  batch_size: 1024

  clean: True
  observables: [
    "density",
    "density_variance",
    "density_density_corr_0",
    "density_density_corr_1",
    "density_density_corr_2",
    "density_density_corr_3",
    "density_squared"
    ]

  base_transforms: null

  train_transforms: 
      _target_: torchvision.transforms.transforms.Compose
      transforms: 
        - _target_: dmb.data.utils.SquareSymmetryGroupTransforms
        - _target_: dmb.data.utils.TupleWrapperInTransform
          transform: 
            _target_: torchvision.transforms.RandomErasing
        - _target_: dmb.data.utils.TupleWrapperOutTransform
          transform: 
            _target_: dmb.data.utils.GaussianNoiseTransform
            mean: 0.0
            std: 0.0075

                 

model:
  model:

    in_channels: 4
    out_channels: 7

    module_list: [
      {
        _target_: dmb.model.models.simple_resnet2d.SeResNet2d,
        in_channels: 4,
        out_channels: 7,
        kernel_sizes: [5,3,3,3,3,3,3],
        n_channels: [16,32,64,128,128,256,256],
        dropout: 0.1
      },
    ]

    output_modification: []

  optimizer:
    lr: 0.005

  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: min
    factor: 0.5
    patience: 200
    min_lr: 1e-4
    verbose: False
    cooldown: 250
    threshold: 0.1

  loss:
    _target_: dmb.model.utils.MaskedMSELoss
    reduction: "mean"