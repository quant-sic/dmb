# @package _global_

defaults:
  - override /datamodule: bose_hubbard_2d
  - override /lit_model: lit_dmb_model
  - override /lit_model/model: dmb_model
  - override /callbacks: default
  - override /trainer: default
  - _self_

exp_name: "bose_hubbard_2d/worm/all_obs/se_resnet/mse/softplus"

seed: 12345

trainer:
  max_epochs: 10000
  accumulate_grad_batches: 8
  precision: 16-mixed
  deterministic: False
  check_val_every_n_epoch: 25

datamodule:

  batch_size: 2048

  dataset:
    transforms: 
      train_augmentations:           
        - _target_: dmb.data.bose_hubbard_2d.transforms.D4GroupTransforms
        - _target_: dmb.data.bose_hubbard_2d.transforms.TupleWrapperOutTransform
          transform: 
            _target_: dmb.data.bose_hubbard_2d.transforms.GaussianNoiseTransform
            mean: 0.0
            std: 0.01
        - _target_: dmb.data.bose_hubbard_2d.transforms.TupleWrapperInTransform
          transform: 
            _target_: torchvision.transforms.RandomErasing

lit_model:
  model:

    module_list: [
      {
        _target_: dmb.model.modules.SeResNet2d,
        in_channels: 4,
        out_channels: 9,
        kernel_sizes: [5,3,3,3,3,3,3,3,3],
        n_channels: [16, 32, 64, 128, 128, 128, 256, 256, 256],
        dropout: 0.1
      },
    ]

    output_modification: [
      _target_: torch.nn.Softplus
    ]

  optimizer:
    lr: 0.00075

  lr_scheduler:
    scheduler:
      _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
      mode: min
      factor: 0.5
      patience: 200
      min_lr: 1e-4
      cooldown: 500
      threshold: 0.1
      
    monitor: train/mse
    interval: epoch
    frequency: 1

  loss:
    _target_: dmb.model.loss.MSELoss
    reduction: mean